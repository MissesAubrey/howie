{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFBertForSequenceClassification, TFRobertaForSequenceClassification\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creation of a subclass in order to define a new serving signature\n",
    "class MyOwnModel(TFRobertaForSequenceClassification):\n",
    "    # Decorate the serving method with the new input_signature\n",
    "    # an input_signature represents the name, the data type and the shape of an expected input\n",
    "    @tf.function(input_signature=[{\n",
    "        \"inputs_embeds\": tf.TensorSpec((None, None, 1024), tf.float32, name=\"inputs_embeds\"),\n",
    "        \"attention_mask\": tf.TensorSpec((None, None), tf.int32, name=\"attention_mask\"),\n",
    "        \"token_type_ids\": tf.TensorSpec((None, None), tf.int32, name=\"token_type_ids\"),\n",
    "    }])\n",
    "    def serving(self, inputs):\n",
    "        # call the model to process the inputs\n",
    "        output = self.call(inputs)\n",
    "\n",
    "        # return the formated output\n",
    "        return self.serving_output(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing MyOwnModel.\n",
      "\n",
      "All the layers of MyOwnModel were initialized from the model checkpoint at roberta-large-mnli.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MyOwnModel for predictions without further training.\n",
      "WARNING:absl:Found untraced functions such as encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, dense_layer_call_fn while saving (showing 5 of 2075). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/roberta/saved_model/1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/roberta/saved_model/1/assets\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Instantiate the model with the new serving method\n",
    "model = MyOwnModel.from_pretrained(\"roberta-large-mnli\") #bert-base-cased\n",
    "# save it with saved_model=True in order to have a SavedModel version along with the h5 weights.\n",
    "model.save_pretrained(\"../models/roberta\", saved_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
